"""
AI Meeting Tool Backend - ä¿®å¾©ç‰ˆæœ¬
ä¿®å¾©å•é¡Œï¼šç¢ºä¿ job status API èƒ½è¿”å›å®Œæ•´çš„è™•ç†çµæœ
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import os
import tempfile
import uuid
import asyncio
from datetime import datetime
import logging
import json

from pathlib import Path # Added for file size
# è‡ªå®šç¾©è™•ç†å™¨
from processors.whisperx_processor import WhisperXProcessor
from processors.openrouter_client import OpenRouterClient
from utils.file_handler import FileHandler

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Pydantic æ¨¡å‹
class AnalyzeTranscriptRequest(BaseModel):
    transcript: List[Dict[str, Any]]
    analysis_type: str = "æœƒè­°æ‘˜è¦"

class ProcessingResponse(BaseModel):
    job_id: str
    status: str
    transcript: Optional[List[Dict[str, Any]]] = None
    speaker_count: Optional[int] = None
    analysis: Optional[str] = None
    processing_time: Optional[float] = None
    language: Optional[str] = None
    analysis_type: Optional[str] = None
    diarization: Optional[Dict[str, Any]] = None
    error: Optional[str] = None

# å»ºç«‹ FastAPI æ‡‰ç”¨
app = FastAPI(
    title="AI Meeting Tool Backend",
    description="åŸºæ–¼ WhisperX å’Œ OpenRouter çš„æœƒè­°éŒ„éŸ³è½‰éŒ„å’Œæ™ºèƒ½åˆ†æ API",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS è¨­ç½®
cors_origins_str = os.getenv("CORS_ORIGINS")
allowed_origins = []
if cors_origins_str:
    allowed_origins = [origin.strip() for origin in cors_origins_str.split(',')]
    logger.info(f"CORS allowed origins configured from env: {allowed_origins}")
else:
    # Default behavior if CORS_ORIGINS is not set
    allowed_origins = ["*"]
    logger.warning("CORS_ORIGINS environment variable not set. Defaulting to allow all origins ('*'). "
                     "For production, it is highly recommended to set specific origins.")

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins, # Use the dynamically configured list
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨åŸŸè®Šæ•¸
processor: Optional[WhisperXProcessor] = None
openrouter: Optional[OpenRouterClient] = None
file_handler_instance: Optional[FileHandler] = None # For FileHandler
processing_jobs = {}

@app.get("/")
async def root():
    """æ ¹ç«¯é» - ç³»çµ±ç‹€æ…‹"""
    return {
        "message": "ğŸ¤– AI Meeting Tool Backend",
        "version": "2.0.0",
        "status": "running",
        "features": [
            "WhisperX èªéŸ³è½‰éŒ„",
            "ç²¾æº–èªªè©±è€…è¾¨è­˜", 
            "OpenRouter AI åˆ†æ",
            "å³æ™‚è™•ç†ç‹€æ…‹"
        ],
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    try:
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "components": {}
        }
        
        # æª¢æŸ¥ WhisperX è™•ç†å™¨
        if processor:
            whisperx_info = processor.get_model_info()
            health_status["components"]["whisperx"] = {
                "status": "ready",
                **whisperx_info
            }
        else:
            health_status["components"]["whisperx"] = {"status": "not_initialized"}
        
        # æª¢æŸ¥ OpenRouter å®¢æˆ¶ç«¯
        if openrouter:
            try:
                # ç°¡å–®çš„é€£æ¥æ¸¬è©¦
                connection_ok = await openrouter.test_connection()
                health_status["components"]["openrouter"] = {
                    "status": "ready" if connection_ok else "connection_failed"
                }
            except Exception as e:
                health_status["components"]["openrouter"] = {
                    "status": "error",
                    "error": str(e)
                }
        else:
            health_status["components"]["openrouter"] = {"status": "not_initialized"}
        
        return health_status
        
    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        raise HTTPException(status_code=503, detail=f"Service unhealthy: {str(e)}")

@app.post("/process-audio", response_model=ProcessingResponse)
async def process_audio(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    language: str = Form("zh"),
    analysis_type: str = Form("æœƒè­°æ‘˜è¦"),
    num_speakers: Optional[int] = Form(None),
    min_speakers: Optional[int] = Form(None),
    max_speakers: Optional[int] = Form(None),
    async_processing: bool = Form(False)
):
    """
    è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ
    
    - **file**: éŸ³è¨Šæª”æ¡ˆ (æ”¯æ´ MP3, WAV, M4A, WEBM, OGG, FLAC)
    - **language**: èªè¨€ä»£ç¢¼ (zh=ä¸­æ–‡, en=è‹±æ–‡, auto=è‡ªå‹•åµæ¸¬)
    - **analysis_type**: åˆ†æé¡å‹ (æœƒè­°æ‘˜è¦, è¡Œå‹•é …ç›®, é‡è¦æ±ºç­–, æ™ºèƒ½åˆ†æ)
    - **num_speakers**: ç²¾ç¢ºèªªè©±è€…æ•¸é‡
    - **min_speakers**: æœ€å°‘èªªè©±è€…æ•¸é‡
    - **max_speakers**: æœ€å¤šèªªè©±è€…æ•¸é‡
    - **async_processing**: æ˜¯å¦èƒŒæ™¯è™•ç†
    """
    
    if not processor or not openrouter:
        raise HTTPException(status_code=503, detail="æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")
    if not file_handler_instance:
        raise HTTPException(status_code=503, detail="FileHandler service is not initialized.")

    job_id = str(uuid.uuid4())
    saved_file_path = None # Initialize here to ensure it's available for finally block if sync

    try:
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹ (early, before file saving, to track job_id)
        start_time = datetime.now()
        processing_jobs[job_id] = {
            "status": "processing",
            "step": "uploading",
            "progress": 1, # Initial progress
            "start_time": start_time,
            "original_filename": file.filename, # Store original filename
            "language": language,
            "analysis_type": analysis_type
        }

        logger.info(f"é–‹å§‹è™•ç†éŸ³è¨Š (Job: {job_id}): {file.filename}")

        # Save file using FileHandler
        try:
            saved_file_path = await file_handler_instance.save_uploaded_file(file, job_id)
            file_size = Path(saved_file_path).stat().st_size
            processing_jobs[job_id].update({
                "saved_file_path": saved_file_path,
                "file_size": file_size,
                "step": "preparing",
                "progress": 5
            })
            logger.info(f"æª”æ¡ˆå·²å„²å­˜: {saved_file_path} (Job: {job_id}), å¤§å°: {file_size} bytes")

        except ValueError as ve: # Catch validation errors from FileHandler
            logger.error(f"æª”æ¡ˆé©—è­‰éŒ¯èª¤ (Job {job_id}): {ve}")
            processing_jobs[job_id].update({"status": "failed", "error": str(ve), "progress": 0})
            raise HTTPException(status_code=400, detail=str(ve))
        except RuntimeError as re: # Catch storage errors from FileHandler
            logger.error(f"æª”æ¡ˆå„²å­˜éŒ¯èª¤ (Job {job_id}): {re}")
            processing_jobs[job_id].update({"status": "failed", "error": str(re), "progress": 0})
            raise HTTPException(status_code=500, detail=str(re))
        except Exception as e: # Catch any other unexpected error during file save
            logger.error(f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ (Job {job_id}): {e}")
            processing_jobs[job_id].update({"status": "failed", "error": f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}", "progress": 0})
            raise HTTPException(status_code=500, detail=f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")

        if async_processing:
            # èƒŒæ™¯è™•ç†
            background_tasks.add_task(
                process_audio_background,
                job_id, saved_file_path, language, analysis_type,
                num_speakers, min_speakers, max_speakers
            )
            return ProcessingResponse(job_id=job_id, status="processing")
        else:
            # åŒæ­¥è™•ç†
            result = await process_audio_sync(
                job_id, saved_file_path, language, analysis_type,
                num_speakers, min_speakers, max_speakers
            )
            return result
            
    except HTTPException as http_exc:
        # Log if not already properly logged by specific file handling errors
        if "error" not in processing_jobs.get(job_id, {}):
             processing_jobs[job_id] = {**processing_jobs.get(job_id, {}), "status": "failed", "error": http_exc.detail}
        raise
    except Exception as e:
        logger.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”Ÿä¸»æµç¨‹éŒ¯èª¤ (Job {job_id}): {e}")
        processing_jobs[job_id] = {**processing_jobs.get(job_id, {}), "status": "failed", "error": str(e), "progress": 0}
        raise HTTPException(status_code=500, detail=f"è™•ç†å¤±æ•—: {str(e)}")
    finally:
        # Synchronous cleanup for synchronous calls.
        # For async, process_audio_sync (called by background task) handles its own cleanup.
        if not async_processing and saved_file_path and file_handler_instance:
            logger.info(f"åŒæ­¥è™•ç†å®Œæˆï¼Œé–‹å§‹æ¸…ç†æª”æ¡ˆ (Job {job_id}): {saved_file_path}")
            file_handler_instance.cleanup_temp_file(saved_file_path)


async def process_audio_sync(
    job_id: str, 
    audio_file_path: str,
    language: str, 
    analysis_type: str,
    num_speakers: Optional[int] = None,
    min_speakers: Optional[int] = None,
    max_speakers: Optional[int] = None
) -> ProcessingResponse:
    """åŒæ­¥è™•ç†éŸ³è¨Š"""
    try:
        # æ›´æ–°ç‹€æ…‹ï¼šé–‹å§‹è½‰éŒ„
        processing_jobs[job_id]["step"] = "transcribing"
        processing_jobs[job_id]["progress"] = 20
        
        logger.info(f"é–‹å§‹ WhisperX è½‰éŒ„ (Job: {job_id})")
        
        # WhisperX è™•ç†
        transcript_result = await processor.process_audio_file(
            audio_file_path=audio_file_path, # Pass path
            language=language,
            num_speakers=num_speakers,
            min_speakers=min_speakers,
            max_speakers=max_speakers
        )
        
        # æ›´æ–°ç‹€æ…‹ï¼šé–‹å§‹ AI åˆ†æ
        processing_jobs[job_id]["step"] = "analyzing"
        processing_jobs[job_id]["progress"] = 75
        
        logger.info(f"é–‹å§‹ AI åˆ†æ: {job_id}")
        
        # OpenRouter åˆ†æ
        analysis = await openrouter.analyze_transcript(
            transcript_result["segments"], 
            analysis_type
        )
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        processing_time = (datetime.now() - processing_jobs[job_id]["start_time"]).total_seconds()
        
        # ğŸ”§ é—œéµä¿®å¾©ï¼šå„²å­˜å®Œæ•´è™•ç†çµæœåˆ° processing_jobs
        processing_jobs[job_id].update({
            "status": "completed",
            "step": "finished",
            "progress": 100,
            "processing_time": processing_time,
            # æ–°å¢ï¼šå„²å­˜å¯¦éš›è™•ç†çµæœ
            "transcript": transcript_result["segments"],
            "speaker_count": transcript_result.get("diarization", {}).get("speaker_count", 0),
            "analysis": analysis,
            "detected_language": transcript_result["metadata"]["detected_language"],
            "diarization": transcript_result.get("diarization")
        })
        
        logger.info(f"è™•ç†å®Œæˆ: {job_id}, è€—æ™‚: {processing_time:.2f}ç§’")
        
        # è¿”å›çµæœ
        return ProcessingResponse(
            job_id=job_id,
            status="completed",
            transcript=transcript_result["segments"],
            speaker_count=transcript_result.get("diarization", {}).get("speaker_count", 0),
            analysis=analysis,
            processing_time=processing_time,
            language=transcript_result["metadata"]["detected_language"],
            analysis_type=analysis_type,
            diarization=transcript_result.get("diarization")
        )
        
    except Exception as e:
        # è™•ç†å¤±æ•—
        processing_jobs[job_id].update({
            "status": "failed",
            "error": str(e),
            "progress": 0 # Reset progress on failure
        })
        logger.error(f"åŒæ­¥éŸ³è¨Šè™•ç†å¤±æ•— (Job {job_id}): {e}")
        raise # Re-raise to be caught by the main endpoint or background task handler
    finally:
        # Cleanup is handled by the caller of process_audio_sync if it's a direct sync call,
        # or here if it's part of a background task.
        # For this structure, if called by background task, it cleans up.
        # If called by sync route, the route's finally block cleans up.
        # To ensure cleanup for background tasks specifically:
        if asyncio.get_event_loop().is_running() and any(task.get_name() == job_id for task in asyncio.all_tasks()): # Heuristic for background
             if file_handler_instance and audio_file_path:
                logger.info(f"èƒŒæ™¯ä»»å‹™å®Œæˆ/å¤±æ•—ï¼Œé–‹å§‹æ¸…ç†æª”æ¡ˆ (Job {job_id}): {audio_file_path}")
                file_handler_instance.cleanup_temp_file(audio_file_path)


async def process_audio_background(
    job_id: str, 
    audio_file_path: str,
    language: str, 
    analysis_type: str,
    num_speakers: Optional[int] = None,
    min_speakers: Optional[int] = None,
    max_speakers: Optional[int] = None
):
    """èƒŒæ™¯è™•ç†éŸ³è¨Š"""
    try:
        await process_audio_sync(
            job_id, audio_file_path, language, analysis_type,
            num_speakers, min_speakers, max_speakers
        )
    except Exception as e:
        logger.error(f"èƒŒæ™¯è™•ç†å¤±æ•— (Job {job_id}): {e}")
        # Ensure job status is updated if process_audio_sync failed to do so
        if job_id in processing_jobs and processing_jobs[job_id].get("status") != "failed":
            processing_jobs[job_id].update({
                "status": "failed",
                "error": f"èƒŒæ™¯ä»»å‹™åŸ·è¡Œå¤±æ•—: {str(e)}",
                "progress": 0
            })
    finally:
        # Ensure cleanup for background tasks, even if process_audio_sync's finally didn't run due to early error
        # This is a fallback, ideally process_audio_sync's finally should always execute.
        # However, if process_audio_sync itself fails to enter its try block, this is needed.
        if file_handler_instance and audio_file_path:
            # Check if file still exists, as process_audio_sync might have cleaned it
            if Path(audio_file_path).exists():
                 logger.info(f"èƒŒæ™¯ä»»å‹™çµæŸï¼Œç¢ºèªæ¸…ç†æª”æ¡ˆ (Job {job_id}): {audio_file_path}")
                 file_handler_instance.cleanup_temp_file(audio_file_path)


@app.post("/analyze-transcript")
async def analyze_transcript(request: AnalyzeTranscriptRequest):
    """åˆ†æå·²æœ‰çš„è½‰éŒ„æ–‡å­—"""
    
    if not openrouter:
        raise HTTPException(status_code=503, detail="OpenRouter æœå‹™å°šæœªåˆå§‹åŒ–")
    
    try:
        analysis = await openrouter.analyze_transcript(
            request.transcript, 
            request.analysis_type
        )
        
        return {
            "status": "completed",
            "analysis": analysis,
            "analysis_type": request.analysis_type,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"åˆ†æè½‰éŒ„æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±æ•—: {str(e)}")

@app.get("/job/{job_id}/status")
async def get_job_status(job_id: str):
    """æŸ¥è©¢ä»»å‹™ç‹€æ…‹ - ğŸ”§ ä¿®å¾©ç‰ˆæœ¬ï¼šè¿”å›å®Œæ•´è™•ç†çµæœ"""
    if job_id not in processing_jobs:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    job_status = processing_jobs[job_id].copy()
    
    # è¨ˆç®—é‹è¡Œæ™‚é–“
    if "start_time" in job_status and job_status["status"] == "processing":
        elapsed_time = (datetime.now() - job_status["start_time"]).total_seconds()
        job_status["elapsed_time"] = elapsed_time
    
    # ç§»é™¤ä¸éœ€è¦çš„å…§éƒ¨è³‡è¨Šï¼Œä½†ä¿ç•™è™•ç†çµæœ
    job_status.pop("start_time", None)
    
    # ğŸ”§ ä¿®å¾©ï¼šç¢ºä¿è¿”å›å®Œæ•´çµæœçµ¦å‰ç«¯
    if job_status["status"] == "completed":
        # ç¢ºä¿åŒ…å«æ‰€æœ‰å‰ç«¯éœ€è¦çš„æ¬„ä½
        return {
            "job_id": job_id,
            "status": job_status["status"],
            "step": job_status.get("step", "finished"),
            "progress": job_status.get("progress", 100),
            "original_filename": job_status.get("original_filename"),
            "language": job_status.get("detected_language", job_status.get("language")),
            "analysis_type": job_status.get("analysis_type"),
            "saved_file_path": job_status.get("saved_file_path"),
            "file_size": job_status.get("file_size"),
            "processing_time": job_status.get("processing_time"),
            # ğŸ¯ é—œéµï¼šè¿”å›å¯¦éš›è™•ç†çµæœ
            "transcript": job_status.get("transcript"),
            "speaker_count": job_status.get("speaker_count"),
            "analysis": job_status.get("analysis"),
            "diarization": job_status.get("diarization")
        }
    
    return job_status

@app.get("/models/info")
async def get_model_info():
    """ç²å–æ¨¡å‹è³‡è¨Š"""
    info = {
        "whisperx": None,
        "openrouter": None,
        "supported_features": []
    }
    
    if processor:
        info["whisperx"] = processor.get_model_info()
        info["supported_features"].append("èªéŸ³è½‰éŒ„")
        if info["whisperx"]["models_loaded"]["diarization"]:
            info["supported_features"].append("èªªè©±è€…è¾¨è­˜")
    
    if openrouter:
        info["openrouter"] = {
            "model": "google/gemma-3-27b-it:free",
            "supported_analysis_types": openrouter.get_supported_analysis_types()
        }
        info["supported_features"].append("AI æ™ºèƒ½åˆ†æ")
    
    info["supported_languages"] = [
        {"code": "zh", "name": "ä¸­æ–‡"},
        {"code": "en", "name": "English"},
        {"code": "ja", "name": "æ—¥æœ¬èª"},
        {"code": "ko", "name": "í•œêµ­ì–´"},
        {"code": "auto", "name": "è‡ªå‹•åµæ¸¬"}
    ]
    
    info["supported_formats"] = [
        "MP3", "WAV", "M4A", "WEBM", "OGG", "FLAC", "OPUS"
    ]
    
    return info

@app.get("/stats")
async def get_stats():
    """ç³»çµ±çµ±è¨ˆè³‡è¨Š"""
    try:
        # ä»»å‹™çµ±è¨ˆ
        total_jobs = len(processing_jobs)
        completed_jobs = sum(1 for job in processing_jobs.values() if job.get("status") == "completed")
        failed_jobs = sum(1 for job in processing_jobs.values() if job.get("status") == "failed")
        processing_count = sum(1 for job in processing_jobs.values() if job.get("status") == "processing")
        
        stats = {
            "jobs": {
                "total": total_jobs,
                "completed": completed_jobs,
                "failed": failed_jobs,
                "processing": processing_count,
                "success_rate": round((completed_jobs / total_jobs * 100), 2) if total_jobs > 0 else 0
            },
            "system": {
                "uptime": "é‹è¡Œä¸­",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # å˜—è©¦ç²å–ç³»çµ±è³‡æºè³‡è¨Š
        try:
            import psutil
            stats["system"].update({
                "cpu_percent": psutil.cpu_percent(interval=0.1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_usage": psutil.disk_usage('/').percent
            })
        except ImportError:
            logger.info("psutil not available, skipping system resource stats")
        
        # GPU è³‡è¨Š
        if processor:
            model_info = processor.get_model_info()
            stats["gpu"] = {
                "cuda_available": model_info["cuda_available"],
                "device": model_info["device"]
            }
        
        return stats
        
    except Exception as e:
        logger.error(f"ç²å–çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
        return {"error": f"ç„¡æ³•ç²å–çµ±è¨ˆè³‡è¨Š: {str(e)}"}

@app.delete("/jobs/{job_id}")
async def delete_job(job_id: str):
    """åˆªé™¤ä»»å‹™è¨˜éŒ„"""
    if job_id not in processing_jobs:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    job_status = processing_jobs[job_id]["status"]
    if job_status == "processing":
        raise HTTPException(status_code=400, detail="ç„¡æ³•åˆªé™¤é€²è¡Œä¸­çš„ä»»å‹™")
    
    del processing_jobs[job_id]
    return {"message": f"ä»»å‹™ {job_id} å·²åˆªé™¤"}

@app.delete("/jobs")
async def clear_completed_jobs():
    """æ¸…ç†å·²å®Œæˆçš„ä»»å‹™"""
    completed_jobs = [
        job_id for job_id, job in processing_jobs.items() 
        if job["status"] in ["completed", "failed"]
    ]
    
    for job_id in completed_jobs:
        del processing_jobs[job_id]
    
    return {"message": f"å·²æ¸…ç† {len(completed_jobs)} å€‹å·²å®Œæˆçš„ä»»å‹™"}

@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•åˆå§‹åŒ–"""
    global processor, openrouter, file_handler_instance
    
    logger.info("ğŸš€ AI Meeting Tool Backend å•Ÿå‹•ä¸­...")
    
    # åˆå§‹åŒ– FileHandler
    try:
        file_handler_instance = FileHandler()
        logger.info(f"âœ… FileHandler initialized. Upload dir: {file_handler_instance.upload_dir}")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize FileHandler: {e}")
        file_handler_instance = None # Ensure it's defined for checks; server might proceed or halt based on policy
        # Depending on policy, might raise an error here to stop server startup
        # raise RuntimeError(f"Critical component FileHandler failed to initialize: {e}") from e

    # æª¢æŸ¥å¿…è¦çš„ç’°å¢ƒè®Šæ•¸
    required_env_vars = ["HF_TOKEN", "OPENROUTER_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"âŒ ç¼ºå°‘å¿…è¦çš„ç’°å¢ƒè®Šæ•¸: {missing_vars}")
        logger.info("è«‹è¨­ç½®ä»¥ä¸‹ç’°å¢ƒè®Šæ•¸ï¼š")
        logger.info("HF_TOKEN - HuggingFace API Token (ç”¨æ–¼èªªè©±è€…è¾¨è­˜)")
        logger.info("OPENROUTER_API_KEY - OpenRouter API Key (ç”¨æ–¼ AI åˆ†æ)")
        raise RuntimeError(f"è«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸: {missing_vars}")
    
    try:
        # åˆå§‹åŒ– WhisperX è™•ç†å™¨
        logger.info("ğŸ“ åˆå§‹åŒ– WhisperX è™•ç†å™¨...")
        model_size = os.getenv("WHISPER_MODEL_SIZE", "base")
        device = os.getenv("DEVICE", "auto")
        language = os.getenv("DEFAULT_LANGUAGE", "zh")
        
        # Read BATCH_SIZE from environment variables
        batch_size_env = os.getenv("BATCH_SIZE", "16")
        batch_size = int(batch_size_env) if batch_size_env.isdigit() else 16

        # Read COMPUTE_TYPE from environment variables
        compute_type = os.getenv("COMPUTE_TYPE", "float16")
        # Optional: Add validation for allowed compute types
        allowed_compute_types = ["float16", "float32", "int8"]
        if compute_type not in allowed_compute_types:
            logger.warning(f"ç„¡æ•ˆçš„ COMPUTE_TYPE: {compute_type}. ä½¿ç”¨é è¨­å€¼ 'float16'.")
            compute_type = "float16"

        processor = WhisperXProcessor(
            model_size=model_size,
            device=device,
            language=language,
            compute_type=compute_type, # Pass the value from env
            batch_size=batch_size    # Pass the value from env
        )
        logger.info(f"âœ… WhisperX è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {model_size}, è¨­å‚™: {device}, èªè¨€: {language}, è¨ˆç®—é¡å‹: {compute_type}, æ‰¹æ¬¡å¤§å°: {batch_size})")
        
        # åˆå§‹åŒ– OpenRouter å®¢æˆ¶ç«¯
        logger.info("ğŸ¤– åˆå§‹åŒ– OpenRouter å®¢æˆ¶ç«¯...")
        openrouter = OpenRouterClient()
        logger.info("âœ… OpenRouter å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆ")
        
        # å»ºç«‹è‡¨æ™‚ç›®éŒ„ (FileHandler now manages its own directories)
        # temp_dir = os.getenv("TEMP_DIR", "/tmp/ai_meeting_tool") # No longer needed here if FileHandler manages
        # os.makedirs(temp_dir, exist_ok=True)
        # logger.info(f"ğŸ“ è‡¨æ™‚ç›®éŒ„å·²å»ºç«‹: {temp_dir}") # Commented out
        
        logger.info("ğŸ‰ AI Meeting Tool Backend å•Ÿå‹•å®Œæˆï¼")
        logger.info("ğŸ“– API æ–‡æª”ï¼šhttp://localhost:8000/docs")
        
    except Exception as e:
        logger.error(f"âŒ å•Ÿå‹•å¤±æ•—: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ¸…ç†"""
    logger.info("ğŸ›‘ AI Meeting Tool Backend æ­£åœ¨é—œé–‰...")
    
    # æ¸…ç†è³‡æº
    if processor:
        try:
            processor._cleanup_memory()
            logger.info("âœ… WhisperX è³‡æºå·²æ¸…ç†")
        except:
            pass
    
    logger.info("ğŸ‘‹ AI Meeting Tool Backend å·²é—œé–‰")

if __name__ == "__main__":
    import uvicorn
    
    # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    reload = os.getenv("RELOAD", "true").lower() == "true"
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )
