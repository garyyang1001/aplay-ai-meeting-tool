from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import os
import tempfile
import uuid
from datetime import datetime
import logging

# è‡ªå®šç¾©æ¨¡çµ„
from processors.whisperx_processor import WhisperXProcessor
from processors.openrouter_client import OpenRouterClient
from models.schemas import ProcessingRequest, ProcessingResponse
from utils.file_handler import FileHandler
from utils.firebase_client import FirebaseClient

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å»ºç«‹ FastAPI æ‡‰ç”¨
app = FastAPI(
    title="AI Meeting Tool Backend",
    description="åŸºæ–¼ WhisperX çš„æœƒè­°éŒ„éŸ³è½‰éŒ„å’Œæ™ºèƒ½åˆ†æ API",
    version="2.0.0"
)

# CORS è¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–è™•ç†å™¨
processor = WhisperXProcessor()
openrouter = OpenRouterClient()
file_handler = FileHandler()
firebase_client = FirebaseClient()

# è™•ç†ä¸­çš„ä»»å‹™å„²å­˜
processing_jobs = {}

@app.get("/")
async def root():
    return {
        "message": "AI Meeting Tool Backend",
        "version": "2.0.0",
        "status": "running",
        "whisperx_ready": processor.is_ready(),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    try:
        # æª¢æŸ¥å„å€‹çµ„ä»¶ç‹€æ…‹
        whisperx_status = processor.health_check()
        openrouter_status = openrouter.health_check()
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "components": {
                "whisperx": whisperx_status,
                "openrouter": openrouter_status,
                "file_handler": "ready"
            }
        }
    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        raise HTTPException(status_code=503, detail="Service unhealthy")

@app.post("/process-audio", response_model=ProcessingResponse)
async def process_audio(
    file: UploadFile = File(...),
    language: str = "zh",
    analysis_type: str = "æœƒè­°æ‘˜è¦",
    num_speakers: int = None,
    background_tasks: BackgroundTasks = None
):
    """è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ"""
    
    job_id = str(uuid.uuid4())
    
    try:
        # é©—è­‰æª”æ¡ˆ
        if not file.filename:
            raise HTTPException(status_code=400, detail="æª”æ¡ˆåç¨±ä¸èƒ½ç‚ºç©º")
        
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size = 0
        content = await file.read()
        file_size = len(content)
        
        max_size = int(os.getenv("MAX_FILE_SIZE", "100")) * 1024 * 1024  # é è¨­ 100MB
        if file_size > max_size:
            raise HTTPException(
                status_code=413, 
                detail=f"æª”æ¡ˆå¤§å°è¶…éé™åˆ¶ ({max_size // 1024 // 1024}MB)"
            )
        
        # é‡ç½®æª”æ¡ˆæŒ‡é‡
        await file.seek(0)
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = datetime.now()
        
        logger.info(f"é–‹å§‹è™•ç†éŸ³è¨Šæª”æ¡ˆ: {file.filename}, å¤§å°: {file_size} bytes, ä»»å‹™ID: {job_id}")
        
        # ä¿å­˜ä¸Šå‚³æª”æ¡ˆ
        audio_path = await file_handler.save_uploaded_file(file, job_id)
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        processing_jobs[job_id] = {
            "status": "processing",
            "step": "transcribing",
            "progress": 10,
            "start_time": start_time
        }
        
        # WhisperX è™•ç†
        logger.info(f"é–‹å§‹ WhisperX è½‰éŒ„: {job_id}")
        transcript_result = processor.process_meeting_audio(
            audio_path, 
            language=language,
            num_speakers=num_speakers
        )
        
        # æ›´æ–°é€²åº¦
        processing_jobs[job_id]["step"] = "analyzing"
        processing_jobs[job_id]["progress"] = 70
        
        # OpenRouter åˆ†æ
        logger.info(f"é–‹å§‹ AI åˆ†æ: {job_id}")
        analysis = await openrouter.analyze_transcript(
            transcript_result["segments"], 
            analysis_type
        )
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # æ¸…ç†æš«å­˜æª”æ¡ˆ
        file_handler.cleanup_temp_file(audio_path)
        
        # å®Œæˆè™•ç†
        processing_jobs[job_id] = {
            "status": "completed",
            "step": "finished",
            "progress": 100
        }
        
        logger.info(f"è™•ç†å®Œæˆ: {job_id}, è€—æ™‚: {processing_time:.2f}ç§’")
        
        return ProcessingResponse(
            job_id=job_id,
            status="completed",
            transcript=transcript_result["segments"],
            speaker_count=len(set(
                seg.get("speaker", "UNKNOWN") 
                for seg in transcript_result["segments"]
            )),
            word_segments=transcript_result.get("word_segments", []),
            analysis=analysis,
            processing_time=processing_time,
            language=language,
            analysis_type=analysis_type
        )
        
    except Exception as e:
        logger.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºå¤±æ•—
        processing_jobs[job_id] = {
            "status": "failed",
            "error": str(e),
            "progress": 0
        }
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æš«å­˜æª”æ¡ˆ
        try:
            if 'audio_path' in locals():
                file_handler.cleanup_temp_file(audio_path)
        except:
            pass
        
        raise HTTPException(status_code=500, detail=f"è™•ç†å¤±æ•—: {str(e)}")

@app.post("/analyze-transcript")
async def analyze_transcript(
    transcript: list,
    analysis_type: str = "æœƒè­°æ‘˜è¦"
):
    """åˆ†æå·²æœ‰çš„è½‰éŒ„æ–‡å­—"""
    try:
        analysis = await openrouter.analyze_transcript(transcript, analysis_type)
        return {
            "status": "completed",
            "analysis": analysis,
            "analysis_type": analysis_type
        }
    except Exception as e:
        logger.error(f"åˆ†æè½‰éŒ„æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±æ•—: {str(e)}")

@app.get("/job/{job_id}/status")
async def get_job_status(job_id: str):
    """æŸ¥è©¢ä»»å‹™ç‹€æ…‹"""
    if job_id not in processing_jobs:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    return processing_jobs[job_id]

@app.get("/models/available")
async def get_available_models():
    """å–å¾—å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    return {
        "whisper_models": [
            "tiny", "base", "small", "medium", "large-v2", "large-v3"
        ],
        "supported_languages": [
            {"code": "zh", "name": "ä¸­æ–‡"},
            {"code": "en", "name": "English"},
            {"code": "ja", "name": "æ—¥æœ¬èª"},
            {"code": "ko", "name": "í•œêµ­ì–´"}
        ],
        "analysis_types": [
            "æœƒè­°æ‘˜è¦", "è¡Œå‹•é …ç›®", "é‡è¦æ±ºç­–", "æ™ºèƒ½åˆ†æ"
        ]
    }

@app.get("/stats")
async def get_stats():
    """å–å¾—ç³»çµ±çµ±è¨ˆè³‡è¨Š"""
    try:
        import psutil
        
        # ç³»çµ±è³‡æº
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # GPU è³‡è¨Šï¼ˆå¦‚æœå¯ç”¨ï¼‰
        gpu_info = processor.get_gpu_info()
        
        # ä»»å‹™çµ±è¨ˆ
        total_jobs = len(processing_jobs)
        completed_jobs = sum(1 for job in processing_jobs.values() if job.get("status") == "completed")
        failed_jobs = sum(1 for job in processing_jobs.values() if job.get("status") == "failed")
        
        return {
            "system": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "disk_percent": (disk.used / disk.total) * 100,
                "gpu_info": gpu_info
            },
            "jobs": {
                "total": total_jobs,
                "completed": completed_jobs,
                "failed": failed_jobs,
                "success_rate": (completed_jobs / total_jobs * 100) if total_jobs > 0 else 0
            }
        }
    except Exception as e:
        logger.error(f"å–å¾—çµ±è¨ˆè³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {"error": "ç„¡æ³•å–å¾—çµ±è¨ˆè³‡è¨Š"}

@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚çš„åˆå§‹åŒ–"""
    logger.info("ğŸš€ AI Meeting Tool Backend å•Ÿå‹•ä¸­...")
    
    # æª¢æŸ¥å¿…è¦çš„ç’°å¢ƒè®Šæ•¸
    required_env_vars = ["HF_TOKEN", "OPENROUTER_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"ç¼ºå°‘å¿…è¦çš„ç’°å¢ƒè®Šæ•¸: {missing_vars}")
        raise RuntimeError(f"è«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸: {missing_vars}")
    
    # åˆå§‹åŒ–è™•ç†å™¨
    try:
        await processor.initialize()
        logger.info("âœ… WhisperX è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ WhisperX è™•ç†å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        raise
    
    # å»ºç«‹å¿…è¦çš„ç›®éŒ„
    upload_dir = os.getenv("UPLOAD_DIR", "/tmp/audio_uploads")
    os.makedirs(upload_dir, exist_ok=True)
    
    logger.info("ğŸ‰ AI Meeting Tool Backend å•Ÿå‹•å®Œæˆï¼")

@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ™‚çš„æ¸…ç†"""
    logger.info("ğŸ›‘ AI Meeting Tool Backend æ­£åœ¨é—œé–‰...")
    
    # æ¸…ç†æš«å­˜æª”æ¡ˆ
    file_handler.cleanup_all_temp_files()
    
    # æ¸…ç†è™•ç†å™¨è³‡æº
    processor.cleanup()
    
    logger.info("ğŸ‘‹ AI Meeting Tool Backend å·²é—œé–‰")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )