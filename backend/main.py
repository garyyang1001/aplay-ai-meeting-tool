"""
AI Meeting Tool Backend - FastAPI ä¸»ç¨‹å¼
æ•´åˆ WhisperX è½‰éŒ„å’Œ OpenRouter AI åˆ†æ
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import os
import tempfile
import uuid
import asyncio
from datetime import datetime
import logging
import json

# è‡ªå®šç¾©è™•ç†å™¨
from processors.whisperx_processor import WhisperXProcessor
from processors.openrouter_client import OpenRouterClient

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Pydantic æ¨¡å‹
class AnalyzeTranscriptRequest(BaseModel):
    transcript: List[Dict[str, Any]]
    analysis_type: str = "æœƒè­°æ‘˜è¦"

class ProcessingResponse(BaseModel):
    job_id: str
    status: str
    transcript: Optional[List[Dict[str, Any]]] = None
    speaker_count: Optional[int] = None
    analysis: Optional[str] = None
    processing_time: Optional[float] = None
    language: Optional[str] = None
    analysis_type: Optional[str] = None
    diarization: Optional[Dict[str, Any]] = None
    error: Optional[str] = None

# å»ºç«‹ FastAPI æ‡‰ç”¨
app = FastAPI(
    title="AI Meeting Tool Backend",
    description="åŸºæ–¼ WhisperX å’Œ OpenRouter çš„æœƒè­°éŒ„éŸ³è½‰éŒ„å’Œæ™ºèƒ½åˆ†æ API",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS è¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨åŸŸè®Šæ•¸
processor: Optional[WhisperXProcessor] = None
openrouter: Optional[OpenRouterClient] = None
processing_jobs = {}

@app.get("/")
async def root():
    """æ ¹ç«¯é» - ç³»çµ±ç‹€æ…‹"""
    return {
        "message": "ğŸ¤– AI Meeting Tool Backend",
        "version": "2.0.0",
        "status": "running",
        "features": [
            "WhisperX èªéŸ³è½‰éŒ„",
            "ç²¾æº–èªªè©±è€…è¾¨è­˜", 
            "OpenRouter AI åˆ†æ",
            "å³æ™‚è™•ç†ç‹€æ…‹"
        ],
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    try:
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "components": {}
        }
        
        # æª¢æŸ¥ WhisperX è™•ç†å™¨
        if processor:
            whisperx_info = processor.get_model_info()
            health_status["components"]["whisperx"] = {
                "status": "ready",
                **whisperx_info
            }
        else:
            health_status["components"]["whisperx"] = {"status": "not_initialized"}
        
        # æª¢æŸ¥ OpenRouter å®¢æˆ¶ç«¯
        if openrouter:
            try:
                # ç°¡å–®çš„é€£æ¥æ¸¬è©¦
                connection_ok = await openrouter.test_connection()
                health_status["components"]["openrouter"] = {
                    "status": "ready" if connection_ok else "connection_failed"
                }
            except Exception as e:
                health_status["components"]["openrouter"] = {
                    "status": "error",
                    "error": str(e)
                }
        else:
            health_status["components"]["openrouter"] = {"status": "not_initialized"}
        
        return health_status
        
    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        raise HTTPException(status_code=503, detail=f"Service unhealthy: {str(e)}")

@app.post("/process-audio", response_model=ProcessingResponse)
async def process_audio(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    language: str = Form("zh"),
    analysis_type: str = Form("æœƒè­°æ‘˜è¦"),
    num_speakers: Optional[int] = Form(None),
    min_speakers: Optional[int] = Form(None),
    max_speakers: Optional[int] = Form(None),
    async_processing: bool = Form(False)
):
    """
    è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ
    
    - **file**: éŸ³è¨Šæª”æ¡ˆ (æ”¯æ´ MP3, WAV, M4A, WEBM, OGG, FLAC)
    - **language**: èªè¨€ä»£ç¢¼ (zh=ä¸­æ–‡, en=è‹±æ–‡, auto=è‡ªå‹•åµæ¸¬)
    - **analysis_type**: åˆ†æé¡å‹ (æœƒè­°æ‘˜è¦, è¡Œå‹•é …ç›®, é‡è¦æ±ºç­–, æ™ºèƒ½åˆ†æ)
    - **num_speakers**: ç²¾ç¢ºèªªè©±è€…æ•¸é‡
    - **min_speakers**: æœ€å°‘èªªè©±è€…æ•¸é‡
    - **max_speakers**: æœ€å¤šèªªè©±è€…æ•¸é‡
    - **async_processing**: æ˜¯å¦èƒŒæ™¯è™•ç†
    """
    
    if not processor or not openrouter:
        raise HTTPException(status_code=503, detail="æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")
    
    job_id = str(uuid.uuid4())
    
    try:
        # é©—è­‰æª”æ¡ˆ
        if not file.filename:
            raise HTTPException(status_code=400, detail="æª”æ¡ˆåç¨±ä¸èƒ½ç‚ºç©º")
        
        # æª¢æŸ¥æª”æ¡ˆæ ¼å¼
        allowed_extensions = {'.mp3', '.wav', '.m4a', '.webm', '.ogg', '.flac', '.opus'}
        file_ext = os.path.splitext(file.filename.lower())[1]
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ {file_ext}ã€‚æ”¯æ´æ ¼å¼ï¼š{', '.join(allowed_extensions)}"
            )
        
        # è®€å–æª”æ¡ˆå…§å®¹
        file_content = await file.read()
        file_size = len(file_content)
        
        # æª¢æŸ¥æª”æ¡ˆå¤§å° (é è¨­ 100MB)
        max_size = int(os.getenv("MAX_FILE_SIZE", "100")) * 1024 * 1024
        if file_size > max_size:
            raise HTTPException(
                status_code=413, 
                detail=f"æª”æ¡ˆå¤§å° {file_size//1024//1024}MB è¶…éé™åˆ¶ {max_size//1024//1024}MB"
            )
        
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        start_time = datetime.now()
        processing_jobs[job_id] = {
            "status": "processing",
            "step": "preparing",
            "progress": 5,
            "start_time": start_time,
            "filename": file.filename,
            "file_size": file_size,
            "language": language,
            "analysis_type": analysis_type
        }
        
        logger.info(f"é–‹å§‹è™•ç†éŸ³è¨Š: {file.filename} ({file_size} bytes), Job: {job_id}")
        
        if async_processing:
            # èƒŒæ™¯è™•ç†
            background_tasks.add_task(
                process_audio_background,
                job_id, file_content, file.filename, language, analysis_type,
                num_speakers, min_speakers, max_speakers
            )
            
            return ProcessingResponse(
                job_id=job_id,
                status="processing"
            )
        else:
            # åŒæ­¥è™•ç†
            result = await process_audio_sync(
                job_id, file_content, file.filename, language, analysis_type,
                num_speakers, min_speakers, max_speakers
            )
            return result
            
    except HTTPException:
        # é‡æ–°æ‹‹å‡º HTTP ç•°å¸¸
        processing_jobs[job_id] = {
            "status": "failed",
            "error": "æª”æ¡ˆé©—è­‰å¤±æ•—"
        }
        raise
    except Exception as e:
        logger.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        processing_jobs[job_id] = {
            "status": "failed",
            "error": str(e),
            "progress": 0
        }
        raise HTTPException(status_code=500, detail=f"è™•ç†å¤±æ•—: {str(e)}")

async def process_audio_sync(
    job_id: str, 
    file_content: bytes, 
    filename: str, 
    language: str, 
    analysis_type: str,
    num_speakers: Optional[int] = None,
    min_speakers: Optional[int] = None,
    max_speakers: Optional[int] = None
) -> ProcessingResponse:
    """åŒæ­¥è™•ç†éŸ³è¨Š"""
    
    try:
        # æ›´æ–°ç‹€æ…‹ï¼šé–‹å§‹è½‰éŒ„
        processing_jobs[job_id]["step"] = "transcribing"
        processing_jobs[job_id]["progress"] = 20
        
        logger.info(f"é–‹å§‹ WhisperX è½‰éŒ„: {job_id}")
        
        # WhisperX è™•ç†
        transcript_result = await processor.process_audio_file(
            file_content=file_content,
            filename=filename,
            language=language,
            num_speakers=num_speakers,
            min_speakers=min_speakers,
            max_speakers=max_speakers
        )
        
        # æ›´æ–°ç‹€æ…‹ï¼šé–‹å§‹ AI åˆ†æ
        processing_jobs[job_id]["step"] = "analyzing"
        processing_jobs[job_id]["progress"] = 75
        
        logger.info(f"é–‹å§‹ AI åˆ†æ: {job_id}")
        
        # OpenRouter åˆ†æ
        analysis = await openrouter.analyze_transcript(
            transcript_result["segments"], 
            analysis_type
        )
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        processing_time = (datetime.now() - processing_jobs[job_id]["start_time"]).total_seconds()
        
        # å®Œæˆè™•ç†
        processing_jobs[job_id] = {
            **processing_jobs[job_id],
            "status": "completed",
            "step": "finished",
            "progress": 100,
            "processing_time": processing_time
        }
        
        logger.info(f"è™•ç†å®Œæˆ: {job_id}, è€—æ™‚: {processing_time:.2f}ç§’")
        
        # è¿”å›çµæœ
        return ProcessingResponse(
            job_id=job_id,
            status="completed",
            transcript=transcript_result["segments"],
            speaker_count=transcript_result.get("diarization", {}).get("speaker_count", 0),
            analysis=analysis,
            processing_time=processing_time,
            language=transcript_result["metadata"]["detected_language"],
            analysis_type=analysis_type,
            diarization=transcript_result.get("diarization")
        )
        
    except Exception as e:
        # è™•ç†å¤±æ•—
        processing_jobs[job_id] = {
            **processing_jobs[job_id],
            "status": "failed",
            "error": str(e),
            "progress": 0
        }
        raise

async def process_audio_background(
    job_id: str, 
    file_content: bytes, 
    filename: str, 
    language: str, 
    analysis_type: str,
    num_speakers: Optional[int] = None,
    min_speakers: Optional[int] = None,
    max_speakers: Optional[int] = None
):
    """èƒŒæ™¯è™•ç†éŸ³è¨Š"""
    try:
        await process_audio_sync(
            job_id, file_content, filename, language, analysis_type,
            num_speakers, min_speakers, max_speakers
        )
    except Exception as e:
        logger.error(f"èƒŒæ™¯è™•ç†å¤±æ•— {job_id}: {e}")

@app.post("/analyze-transcript")
async def analyze_transcript(request: AnalyzeTranscriptRequest):
    """åˆ†æå·²æœ‰çš„è½‰éŒ„æ–‡å­—"""
    
    if not openrouter:
        raise HTTPException(status_code=503, detail="OpenRouter æœå‹™å°šæœªåˆå§‹åŒ–")
    
    try:
        analysis = await openrouter.analyze_transcript(
            request.transcript, 
            request.analysis_type
        )
        
        return {
            "status": "completed",
            "analysis": analysis,
            "analysis_type": request.analysis_type,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"åˆ†æè½‰éŒ„æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±æ•—: {str(e)}")

@app.get("/job/{job_id}/status")
async def get_job_status(job_id: str):
    """æŸ¥è©¢ä»»å‹™ç‹€æ…‹"""
    if job_id not in processing_jobs:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    job_status = processing_jobs[job_id].copy()
    
    # è¨ˆç®—é‹è¡Œæ™‚é–“
    if "start_time" in job_status and job_status["status"] == "processing":
        elapsed_time = (datetime.now() - job_status["start_time"]).total_seconds()
        job_status["elapsed_time"] = elapsed_time
    
    # ç§»é™¤ä¸éœ€è¦çš„å…§éƒ¨è³‡è¨Š
    job_status.pop("start_time", None)
    
    return job_status

@app.get("/models/info")
async def get_model_info():
    """ç²å–æ¨¡å‹è³‡è¨Š"""
    info = {
        "whisperx": None,
        "openrouter": None,
        "supported_features": []
    }
    
    if processor:
        info["whisperx"] = processor.get_model_info()
        info["supported_features"].append("èªéŸ³è½‰éŒ„")
        if info["whisperx"]["models_loaded"]["diarization"]:
            info["supported_features"].append("èªªè©±è€…è¾¨è­˜")
    
    if openrouter:
        info["openrouter"] = {
            "model": "google/gemma-3-27b-it:free",
            "supported_analysis_types": openrouter.get_supported_analysis_types()
        }
        info["supported_features"].append("AI æ™ºèƒ½åˆ†æ")
    
    info["supported_languages"] = [
        {"code": "zh", "name": "ä¸­æ–‡"},
        {"code": "en", "name": "English"},
        {"code": "ja", "name": "æ—¥æœ¬èª"},
        {"code": "ko", "name": "í•œêµ­ì–´"},
        {"code": "auto", "name": "è‡ªå‹•åµæ¸¬"}
    ]
    
    info["supported_formats"] = [
        "MP3", "WAV", "M4A", "WEBM", "OGG", "FLAC", "OPUS"
    ]
    
    return info

@app.get("/stats")
async def get_stats():
    """ç³»çµ±çµ±è¨ˆè³‡è¨Š"""
    try:
        # ä»»å‹™çµ±è¨ˆ
        total_jobs = len(processing_jobs)
        completed_jobs = sum(1 for job in processing_jobs.values() if job.get("status") == "completed")
        failed_jobs = sum(1 for job in processing_jobs.values() if job.get("status") == "failed")
        processing_count = sum(1 for job in processing_jobs.values() if job.get("status") == "processing")
        
        stats = {
            "jobs": {
                "total": total_jobs,
                "completed": completed_jobs,
                "failed": failed_jobs,
                "processing": processing_count,
                "success_rate": round((completed_jobs / total_jobs * 100), 2) if total_jobs > 0 else 0
            },
            "system": {
                "uptime": "é‹è¡Œä¸­",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # å˜—è©¦ç²å–ç³»çµ±è³‡æºè³‡è¨Š
        try:
            import psutil
            stats["system"].update({
                "cpu_percent": psutil.cpu_percent(interval=0.1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_usage": psutil.disk_usage('/').percent
            })
        except ImportError:
            logger.info("psutil not available, skipping system resource stats")
        
        # GPU è³‡è¨Š
        if processor:
            model_info = processor.get_model_info()
            stats["gpu"] = {
                "cuda_available": model_info["cuda_available"],
                "device": model_info["device"]
            }
        
        return stats
        
    except Exception as e:
        logger.error(f"ç²å–çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
        return {"error": f"ç„¡æ³•ç²å–çµ±è¨ˆè³‡è¨Š: {str(e)}"}

@app.delete("/jobs/{job_id}")
async def delete_job(job_id: str):
    """åˆªé™¤ä»»å‹™è¨˜éŒ„"""
    if job_id not in processing_jobs:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    job_status = processing_jobs[job_id]["status"]
    if job_status == "processing":
        raise HTTPException(status_code=400, detail="ç„¡æ³•åˆªé™¤é€²è¡Œä¸­çš„ä»»å‹™")
    
    del processing_jobs[job_id]
    return {"message": f"ä»»å‹™ {job_id} å·²åˆªé™¤"}

@app.delete("/jobs")
async def clear_completed_jobs():
    """æ¸…ç†å·²å®Œæˆçš„ä»»å‹™"""
    completed_jobs = [
        job_id for job_id, job in processing_jobs.items() 
        if job["status"] in ["completed", "failed"]
    ]
    
    for job_id in completed_jobs:
        del processing_jobs[job_id]
    
    return {"message": f"å·²æ¸…ç† {len(completed_jobs)} å€‹å·²å®Œæˆçš„ä»»å‹™"}

@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•åˆå§‹åŒ–"""
    global processor, openrouter
    
    logger.info("ğŸš€ AI Meeting Tool Backend å•Ÿå‹•ä¸­...")
    
    # æª¢æŸ¥å¿…è¦çš„ç’°å¢ƒè®Šæ•¸
    required_env_vars = ["HF_TOKEN", "OPENROUTER_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"âŒ ç¼ºå°‘å¿…è¦çš„ç’°å¢ƒè®Šæ•¸: {missing_vars}")
        logger.info("è«‹è¨­ç½®ä»¥ä¸‹ç’°å¢ƒè®Šæ•¸ï¼š")
        logger.info("HF_TOKEN - HuggingFace API Token (ç”¨æ–¼èªªè©±è€…è¾¨è­˜)")
        logger.info("OPENROUTER_API_KEY - OpenRouter API Key (ç”¨æ–¼ AI åˆ†æ)")
        raise RuntimeError(f"è«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸: {missing_vars}")
    
    try:
        # åˆå§‹åŒ– WhisperX è™•ç†å™¨
        logger.info("ğŸ“ åˆå§‹åŒ– WhisperX è™•ç†å™¨...")
        model_size = os.getenv("WHISPER_MODEL_SIZE", "base")
        device = os.getenv("DEVICE", "auto")
        language = os.getenv("DEFAULT_LANGUAGE", "zh")
        
        processor = WhisperXProcessor(
            model_size=model_size,
            device=device,
            language=language
        )
        logger.info(f"âœ… WhisperX è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {model_size}, è¨­å‚™: {device})")
        
        # åˆå§‹åŒ– OpenRouter å®¢æˆ¶ç«¯
        logger.info("ğŸ¤– åˆå§‹åŒ– OpenRouter å®¢æˆ¶ç«¯...")
        openrouter = OpenRouterClient()
        logger.info("âœ… OpenRouter å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆ")
        
        # å»ºç«‹è‡¨æ™‚ç›®éŒ„
        temp_dir = os.getenv("TEMP_DIR", "/tmp/ai_meeting_tool")
        os.makedirs(temp_dir, exist_ok=True)
        logger.info(f"ğŸ“ è‡¨æ™‚ç›®éŒ„å·²å»ºç«‹: {temp_dir}")
        
        logger.info("ğŸ‰ AI Meeting Tool Backend å•Ÿå‹•å®Œæˆï¼")
        logger.info("ğŸ“– API æ–‡æª”ï¼šhttp://localhost:8000/docs")
        
    except Exception as e:
        logger.error(f"âŒ å•Ÿå‹•å¤±æ•—: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ¸…ç†"""
    logger.info("ğŸ›‘ AI Meeting Tool Backend æ­£åœ¨é—œé–‰...")
    
    # æ¸…ç†è³‡æº
    if processor:
        try:
            processor._cleanup_memory()
            logger.info("âœ… WhisperX è³‡æºå·²æ¸…ç†")
        except:
            pass
    
    logger.info("ğŸ‘‹ AI Meeting Tool Backend å·²é—œé–‰")

if __name__ == "__main__":
    import uvicorn
    
    # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    reload = os.getenv("RELOAD", "true").lower() == "true"
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )
