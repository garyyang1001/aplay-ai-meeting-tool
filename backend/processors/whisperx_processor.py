import os
import torch
import whisperx
import logging
from datetime import datetime
from typing import Dict, List, Optional, Union

logger = logging.getLogger(__name__)

class WhisperXProcessor:
    """
    WhisperX éŸ³è¨Šè™•ç†å™¨
    æ•´åˆèªéŸ³è½‰éŒ„å’Œèªªè©±è€…è¾¨è­˜åŠŸèƒ½
    """
    
    def __init__(self):
        self.device = self._get_device()
        self.batch_size = int(os.getenv('BATCH_SIZE', 16))
        self.compute_type = os.getenv('COMPUTE_TYPE', 'float16')
        self.model_size = os.getenv('DEFAULT_MODEL_SIZE', 'large-v2')
        
        # æ¨¡å‹å¿«å–
        self.whisper_model = None
        self.align_models = {}  # èªè¨€ç‰¹å®šçš„å°é½Šæ¨¡å‹
        self.diarization_pipeline = None
        
        logger.info(f"WhisperX è™•ç†å™¨åˆå§‹åŒ–ï¼šè¨­å‚™={self.device}, æ¨¡å‹={self.model_size}")
    
    def _get_device(self) -> str:
        """è‡ªå‹•åµæ¸¬æœ€ä½³è¨­å‚™"""
        device_setting = os.getenv('DEVICE', 'auto')
        
        if device_setting == 'auto':
            if torch.cuda.is_available():
                return 'cuda'
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return 'mps'  # Apple Silicon GPU
            else:
                return 'cpu'
        
        return device_setting
    
    async def initialize(self):
        """åˆå§‹åŒ–è™•ç†å™¨å’Œæ¨¡å‹"""
        try:
            # é è¼‰å…¥ Whisper æ¨¡å‹
            logger.info(f"è¼‰å…¥ Whisper æ¨¡å‹: {self.model_size}")
            self.whisper_model = whisperx.load_model(
                self.model_size,
                self.device,
                compute_type=self.compute_type
            )
            
            # é è¼‰å…¥èªªè©±è€…è¾¨è­˜æ¨¡å‹
            hf_token = os.getenv('HF_TOKEN')
            if hf_token:
                logger.info("è¼‰å…¥èªªè©±è€…è¾¨è­˜æ¨¡å‹")
                self.diarization_pipeline = whisperx.DiarizationPipeline(
                    use_auth_token=hf_token,
                    device=self.device
                )
            else:
                logger.warning("æœªè¨­å®š HF_TOKENï¼Œèªªè©±è€…è¾¨è­˜åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
            
            logger.info("âœ… WhisperX è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ WhisperX è™•ç†å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def is_ready(self) -> bool:
        """æª¢æŸ¥è™•ç†å™¨æ˜¯å¦å°±ç·’"""
        return self.whisper_model is not None
    
    def health_check(self) -> Dict[str, Union[str, bool]]:
        """å¥åº·æª¢æŸ¥"""
        try:
            # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
            model_ready = self.whisper_model is not None
            diarization_ready = self.diarization_pipeline is not None
            
            # æª¢æŸ¥ GPU è¨˜æ†¶é«”ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
            gpu_info = self.get_gpu_info()
            
            return {
                "status": "ready" if model_ready else "not_ready",
                "whisper_model": model_ready,
                "diarization": diarization_ready,
                "device": self.device,
                "gpu_info": gpu_info
            }
        except Exception as e:
            logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
            return {"status": "error", "error": str(e)}
    
    def get_gpu_info(self) -> Optional[Dict]:
        """å–å¾— GPU è³‡è¨Š"""
        try:
            if self.device == 'cuda' and torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                current_device = torch.cuda.current_device()
                
                return {
                    "available": True,
                    "device_count": gpu_count,
                    "current_device": current_device,
                    "device_name": torch.cuda.get_device_name(current_device),
                    "memory_allocated": torch.cuda.memory_allocated(current_device),
                    "memory_reserved": torch.cuda.memory_reserved(current_device)
                }
            return {"available": False, "reason": "CUDA not available"}
        except Exception as e:
            return {"available": False, "error": str(e)}
    
    def process_meeting_audio(
        self, 
        audio_path: str, 
        language: str = "zh",
        num_speakers: Optional[int] = None,
        min_speakers: Optional[int] = None,
        max_speakers: Optional[int] = None
    ) -> Dict:
        """
        è™•ç†æœƒè­°éŸ³è¨Šï¼šè½‰éŒ„ + èªªè©±è€…è¾¨è­˜
        
        Args:
            audio_path: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
            language: èªè¨€ä»£ç¢¼ (zh, en, ja, ko)
            num_speakers: å›ºå®šèªªè©±è€…æ•¸é‡
            min_speakers: æœ€å°‘èªªè©±è€…æ•¸é‡
            max_speakers: æœ€å¤šèªªè©±è€…æ•¸é‡
        
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        start_time = datetime.now()
        
        try:
            logger.info(f"é–‹å§‹è™•ç†éŸ³è¨Š: {audio_path}, èªè¨€: {language}")
            
            # 1. è¼‰å…¥éŸ³è¨Š
            audio = whisperx.load_audio(audio_path)
            audio_duration = len(audio) / 16000  # å‡è¨­ 16kHz æ¡æ¨£ç‡
            
            logger.info(f"éŸ³è¨Šæ™‚é•·: {audio_duration:.2f} ç§’")
            
            # 2. èªéŸ³è½‰éŒ„
            logger.info("é–‹å§‹èªéŸ³è½‰éŒ„...")
            result = self.whisper_model.transcribe(
                audio,
                batch_size=self.batch_size,
                language=language
            )
            
            # 3. è©ç´šå°é½Š
            logger.info("é–‹å§‹è©ç´šå°é½Š...")
            align_model, metadata = self._get_align_model(language)
            
            if align_model:
                result = whisperx.align(
                    result["segments"],
                    align_model,
                    metadata,
                    audio,
                    self.device,
                    return_char_alignments=False
                )
            
            # 4. èªªè©±è€…è¾¨è­˜
            if self.diarization_pipeline:
                logger.info("é–‹å§‹èªªè©±è€…è¾¨è­˜...")
                
                # è¨­å®šèªªè©±è€…åƒæ•¸
                diarization_params = {}
                if num_speakers:
                    diarization_params['num_speakers'] = num_speakers
                if min_speakers:
                    diarization_params['min_speakers'] = min_speakers
                if max_speakers:
                    diarization_params['max_speakers'] = max_speakers
                
                diarize_segments = self.diarization_pipeline(
                    audio, **diarization_params
                )
                
                # åˆ†é…èªªè©±è€…æ¨™ç±¤
                result = whisperx.assign_word_speakers(
                    diarize_segments, result
                )
            else:
                logger.warning("èªªè©±è€…è¾¨è­˜ä¸å¯ç”¨ï¼Œè·³éæ­¤æ­¥é©Ÿ")
            
            # 5. è™•ç†çµæœ
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # è¨ˆç®—èªªè©±è€…çµ±è¨ˆ
            segments = result.get("segments", [])
            speakers = set()
            for segment in segments:
                if "speaker" in segment and segment["speaker"]:
                    speakers.add(segment["speaker"])
            
            logger.info(f"è™•ç†å®Œæˆï¼Œè€—æ™‚: {processing_time:.2f}ç§’, ç™¼ç¾ {len(speakers)} ä½èªªè©±è€…")
            
            return {
                "segments": segments,
                "word_segments": result.get("word_segments", []),
                "language": language,
                "audio_duration": audio_duration,
                "processing_time": processing_time,
                "speaker_count": len(speakers),
                "speakers": list(speakers),
                "real_time_factor": processing_time / audio_duration if audio_duration > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise RuntimeError(f"éŸ³è¨Šè™•ç†å¤±æ•—: {str(e)}")
    
    def _get_align_model(self, language: str):
        """å–å¾—æˆ–è¼‰å…¥èªè¨€ç‰¹å®šçš„å°é½Šæ¨¡å‹"""
        try:
            if language not in self.align_models:
                logger.info(f"è¼‰å…¥ {language} å°é½Šæ¨¡å‹")
                model, metadata = whisperx.load_align_model(
                    language_code=language,
                    device=self.device
                )
                self.align_models[language] = (model, metadata)
            
            return self.align_models[language]
        except Exception as e:
            logger.warning(f"ç„¡æ³•è¼‰å…¥ {language} å°é½Šæ¨¡å‹: {e}")
            return None, None
    
    def process_audio_chunk(
        self, 
        audio_chunk: bytes, 
        language: str = "zh"
    ) -> Dict:
        """
        è™•ç†éŸ³è¨Šç‰‡æ®µï¼ˆç”¨æ–¼å³æ™‚è™•ç†ï¼‰
        
        Args:
            audio_chunk: éŸ³è¨Šç‰‡æ®µä½å…ƒçµ„
            language: èªè¨€ä»£ç¢¼
        
        Returns:
            éƒ¨åˆ†è™•ç†çµæœ
        """
        try:
            # é€™è£¡å¯ä»¥å¯¦ä½œå³æ™‚è™•ç†é‚è¼¯
            # ç›®å‰ç°¡åŒ–ç‚ºå‘¼å«å®Œæ•´è™•ç†
            # å¯¦éš›å¯¦ä½œéœ€è¦éŸ³è¨Šç·©è¡å€ç®¡ç†
            
            logger.info("è™•ç†éŸ³è¨Šç‰‡æ®µï¼ˆç°¡åŒ–å¯¦ä½œï¼‰")
            
            return {
                "status": "chunk_processed",
                "partial_result": [],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è™•ç†éŸ³è¨Šç‰‡æ®µæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise RuntimeError(f"éŸ³è¨Šç‰‡æ®µè™•ç†å¤±æ•—: {str(e)}")
    
    def estimate_processing_time(self, audio_duration: float) -> float:
        """
        ä¼°ç®—è™•ç†æ™‚é–“
        
        Args:
            audio_duration: éŸ³è¨Šæ™‚é•·ï¼ˆç§’ï¼‰
        
        Returns:
            é ä¼°è™•ç†æ™‚é–“ï¼ˆç§’ï¼‰
        """
        # åŸºæ–¼ç¶“é©—çš„ä¼°ç®—å…¬å¼
        base_factor = 0.05  # åŸºç¤è™•ç†ä¿‚æ•¸
        
        if self.device == 'cuda':
            device_factor = 1.0
        elif self.device == 'mps':
            device_factor = 1.5
        else:
            device_factor = 3.0
        
        model_factor = {
            'tiny': 0.5,
            'base': 0.7,
            'small': 1.0,
            'medium': 1.5,
            'large-v2': 2.0,
            'large-v3': 2.2
        }.get(self.model_size, 2.0)
        
        estimated_time = audio_duration * base_factor * device_factor * model_factor
        
        return max(estimated_time, 5.0)  # æœ€å°‘ 5 ç§’è™•ç†æ™‚é–“
    
    def cleanup(self):
        """
        æ¸…ç†è³‡æº
        """
        try:
            # æ¸…ç† GPU è¨˜æ†¶é«”
            if self.device == 'cuda' and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # é‡ç½®æ¨¡å‹å¼•ç”¨
            self.whisper_model = None
            self.align_models.clear()
            self.diarization_pipeline = None
            
            logger.info("ğŸ§¹ WhisperX è™•ç†å™¨è³‡æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†è³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def get_supported_languages(self) -> List[Dict[str, str]]:
        """
        å–å¾—æ”¯æ´çš„èªè¨€åˆ—è¡¨
        """
        return [
            {"code": "zh", "name": "ä¸­æ–‡", "whisper_support": True, "align_support": True},
            {"code": "en", "name": "English", "whisper_support": True, "align_support": True},
            {"code": "ja", "name": "æ—¥æœ¬èª", "whisper_support": True, "align_support": True},
            {"code": "ko", "name": "í•œêµ­ì–´", "whisper_support": True, "align_support": False},
            {"code": "es", "name": "EspaÃ±ol", "whisper_support": True, "align_support": True},
            {"code": "fr", "name": "FranÃ§ais", "whisper_support": True, "align_support": True},
            {"code": "de", "name": "Deutsch", "whisper_support": True, "align_support": True},
            {"code": "it", "name": "Italiano", "whisper_support": True, "align_support": True},
            {"code": "pt", "name": "PortuguÃªs", "whisper_support": True, "align_support": True}
        ]