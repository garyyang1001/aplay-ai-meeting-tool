#!/usr/bin/env python3
"""
WhisperX æ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰ WhisperX å®‰è£å’ŒåŸºæœ¬åŠŸèƒ½
"""

import os
import sys
import logging
import tempfile
from pathlib import Path

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_imports():
    """æ¸¬è©¦å¿…è¦æ¨¡çµ„å°å…¥"""
    logger.info("ğŸ” æ¸¬è©¦æ¨¡çµ„å°å…¥...")
    
    try:
        import torch
        logger.info(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        
        import whisperx
        logger.info("âœ… WhisperX å°å…¥æˆåŠŸ")
        
        # æª¢æŸ¥ CUDA
        cuda_available = torch.cuda.is_available()
        logger.info(f"ğŸ–¥ï¸  CUDA å¯ç”¨: {cuda_available}")
        
        if cuda_available:
            logger.info(f"ğŸ“Š GPU æ•¸é‡: {torch.cuda.device_count()}")
            logger.info(f"ğŸ¯ ç•¶å‰ GPU: {torch.cuda.get_device_name()}")
        
        # æª¢æŸ¥ MPS (Apple Silicon)
        if hasattr(torch.backends, 'mps'):
            mps_available = torch.backends.mps.is_available()
            logger.info(f"ğŸ MPS å¯ç”¨: {mps_available}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
        return False

def test_whisper_model():
    """æ¸¬è©¦ Whisper æ¨¡å‹è¼‰å…¥"""
    logger.info("ğŸ” æ¸¬è©¦ Whisper æ¨¡å‹è¼‰å…¥...")
    
    try:
        import whisperx
        import torch
        
        # è‡ªå‹•é¸æ“‡è¨­å‚™
        if torch.cuda.is_available():
            device = "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = "mps"
        else:
            device = "cpu"
        
        logger.info(f"ğŸ“± ä½¿ç”¨è¨­å‚™: {device}")
        
        # è¼‰å…¥è¼ƒå°çš„æ¨¡å‹é€²è¡Œæ¸¬è©¦
        model = whisperx.load_model("tiny", device)
        logger.info("âœ… Whisper æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        
        # æ¸…ç†
        del model
        if device == "cuda":
            torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Whisper æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return False

def test_diarization():
    """æ¸¬è©¦èªªè©±è€…è¾¨è­˜"""
    logger.info("ğŸ” æ¸¬è©¦èªªè©±è€…è¾¨è­˜...")
    
    hf_token = os.getenv('HF_TOKEN')
    if not hf_token:
        logger.warning("âš ï¸  æœªè¨­å®š HF_TOKENï¼Œè·³éèªªè©±è€…è¾¨è­˜æ¸¬è©¦")
        return True
    
    try:
        import whisperx
        import torch
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # è¼‰å…¥èªªè©±è€…è¾¨è­˜æ¨¡å‹
        diarize_model = whisperx.DiarizationPipeline(
            use_auth_token=hf_token,
            device=device
        )
        logger.info("âœ… èªªè©±è€…è¾¨è­˜æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        
        # æ¸…ç†
        del diarize_model
        if device == "cuda":
            torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ èªªè©±è€…è¾¨è­˜æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        logger.error("è«‹ç¢ºä¿å·²æ¥å— HuggingFace æ¨¡å‹ä½¿ç”¨æ¢æ¬¾:")
        logger.error("- https://huggingface.co/pyannote/speaker-diarization-3.1")
        logger.error("- https://huggingface.co/pyannote/segmentation-3.0")
        return False

def test_audio_processing():
    """æ¸¬è©¦éŸ³è¨Šè™•ç†ï¼ˆå¦‚æœæœ‰æ¸¬è©¦æª”æ¡ˆï¼‰"""
    logger.info("ğŸ” æ¸¬è©¦éŸ³è¨Šè™•ç†...")
    
    # å°‹æ‰¾æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆ
    test_files = [
        "test_audio.wav",
        "sample.wav", 
        "test.mp3",
        "../test_audio.wav"
    ]
    
    test_file = None
    for file_path in test_files:
        if Path(file_path).exists():
            test_file = file_path
            break
    
    if not test_file:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆï¼Œè·³ééŸ³è¨Šè™•ç†æ¸¬è©¦")
        logger.info("ğŸ’¡ ä½ å¯ä»¥æ”¾ç½®ä¸€å€‹ test_audio.wav æª”æ¡ˆä¾†æ¸¬è©¦å®Œæ•´åŠŸèƒ½")
        return True
    
    try:
        import whisperx
        import torch
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        logger.info(f"ğŸµ è™•ç†æ¸¬è©¦æª”æ¡ˆ: {test_file}")
        
        # è¼‰å…¥æ¨¡å‹
        model = whisperx.load_model("tiny", device)
        
        # è¼‰å…¥éŸ³è¨Š
        audio = whisperx.load_audio(test_file)
        logger.info(f"ğŸ“Š éŸ³è¨Šæ™‚é•·: {len(audio)/16000:.2f} ç§’")
        
        # è½‰éŒ„
        result = model.transcribe(audio, batch_size=4)
        logger.info(f"ğŸ“ è½‰éŒ„ç‰‡æ®µæ•¸: {len(result['segments'])}")
        
        # é¡¯ç¤ºç¬¬ä¸€å€‹ç‰‡æ®µ
        if result['segments']:
            first_segment = result['segments'][0]
            logger.info(f"ğŸ“– ç¬¬ä¸€å€‹ç‰‡æ®µ: {first_segment['text'][:50]}...")
        
        logger.info("âœ… éŸ³è¨Šè™•ç†æ¸¬è©¦æˆåŠŸ")
        
        # æ¸…ç†
        del model
        if device == "cuda":
            torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ éŸ³è¨Šè™•ç†æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_environment():
    """æ¸¬è©¦ç’°å¢ƒè¨­å®š"""
    logger.info("ğŸ” æª¢æŸ¥ç’°å¢ƒè¨­å®š...")
    
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    hf_token = os.getenv('HF_TOKEN')
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    
    logger.info(f"ğŸ”‘ HF_TOKEN: {'âœ… å·²è¨­å®š' if hf_token else 'âŒ æœªè¨­å®š'}")
    logger.info(f"ğŸ”‘ OPENROUTER_API_KEY: {'âœ… å·²è¨­å®š' if openrouter_key else 'âŒ æœªè¨­å®š'}")
    
    # æª¢æŸ¥å¿…è¦ç›®éŒ„
    upload_dir = os.getenv('UPLOAD_DIR', '/tmp/audio_uploads')
    Path(upload_dir).mkdir(parents=True, exist_ok=True)
    logger.info(f"ğŸ“ ä¸Šå‚³ç›®éŒ„: {upload_dir}")
    
    # æª¢æŸ¥ FFmpeg
    try:
        import subprocess
        result = subprocess.run(['ffmpeg', '-version'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            logger.info("âœ… FFmpeg å¯ç”¨")
        else:
            logger.warning("âš ï¸  FFmpeg ä¸å¯ç”¨")
    except:
        logger.warning("âš ï¸  FFmpeg ä¸å¯ç”¨")
    
    return True

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹ WhisperX æ¸¬è©¦")
    logger.info("=" * 50)
    
    tests = [
        ("æ¨¡çµ„å°å…¥", test_imports),
        ("ç’°å¢ƒè¨­å®š", test_environment),
        ("Whisper æ¨¡å‹", test_whisper_model),
        ("èªªè©±è€…è¾¨è­˜", test_diarization),
        ("éŸ³è¨Šè™•ç†", test_audio_processing)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ {test_name} æ¸¬è©¦:")
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            logger.error(f"æ¸¬è©¦ {test_name} æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
            results.append((test_name, False))
    
    # é¡¯ç¤ºæ¸¬è©¦çµæœ
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š æ¸¬è©¦çµæœæ‘˜è¦:")
    
    for test_name, success in results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        logger.info(f"  {test_name}: {status}")
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    logger.info(f"\nğŸ¯ ç¸½çµ: {passed}/{total} é …æ¸¬è©¦é€šé")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼WhisperX å·²æº–å‚™å°±ç·’ã€‚")
        return 0
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤è¨Šæ¯ã€‚")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)