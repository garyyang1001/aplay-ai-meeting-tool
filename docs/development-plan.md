# é–‹ç™¼è¨ˆç•« v2.0 - WhisperX æ–¹æ¡ˆ

## ğŸ“… ç¸½æ™‚ç¨‹ï¼š2é€±å®Œæˆ MVP

### Week 1: æ ¸å¿ƒåŠŸèƒ½å¯¦ä½œ

#### Day 1-2: Mac Mini ç’°å¢ƒè¨­ç½®

**ç’°å¢ƒæº–å‚™**
```bash
# 1. å®‰è£ Python ç’°å¢ƒ
python3 -m venv whisperx-env
source whisperx-env/bin/activate

# 2. å®‰è£ WhisperX
pip install whisperx
# æˆ–æœ€æ–°ç‰ˆæœ¬
pip install git+https://github.com/m-bain/whisperx.git

# 3. å®‰è£å…¶ä»–ä¾è³´
pip install fastapi uvicorn redis celery
pip install firebase-admin

# 4. è¨­ç½® HuggingFace Token
export HF_TOKEN="your_huggingface_token"

# 5. æ¸¬è©¦ GPU æ”¯æ´
python -c "import torch; print(torch.cuda.is_available())"
```

**æ¸¬è©¦ WhisperX**
```python
# test_whisperx.py
import whisperx

# æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisperx.load_model("base", device)
audio = whisperx.load_audio("test_audio.wav")
result = model.transcribe(audio)
print(result["segments"])
```

#### Day 3-4: å¾Œç«¯ API é–‹ç™¼

**FastAPI æœå‹™çµæ§‹**
```
backend/
â”œâ”€â”€ main.py              # FastAPI ä¸»ç¨‹å¼
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ whisperx_processor.py  # WhisperX è™•ç†å™¨
â”‚   â””â”€â”€ openrouter_client.py   # OpenRouter å®¢æˆ¶ç«¯
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py       # è³‡æ–™æ¨¡å‹
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ firebase_client.py     # Firebase æ•´åˆ
â”‚   â””â”€â”€ file_handler.py        # æª”æ¡ˆè™•ç†
â”œâ”€â”€ workers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ celery_tasks.py        # èƒŒæ™¯ä»»å‹™
â””â”€â”€ requirements.txt
```

**æ ¸å¿ƒ API ç«¯é»**
```python
# main.py
from fastapi import FastAPI, UploadFile, BackgroundTasks
from processors.whisperx_processor import WhisperXProcessor
from processors.openrouter_client import OpenRouterClient

app = FastAPI(title="AI Meeting Tool Backend")
processor = WhisperXProcessor()
openrouter = OpenRouterClient()

@app.post("/process-audio")
async def process_audio(
    file: UploadFile,
    language: str = "zh",
    analysis_type: str = "æœƒè­°æ‘˜è¦",
    background_tasks: BackgroundTasks = None
):
    """è™•ç†ä¸Šå‚³çš„éŸ³è¨Šæª”æ¡ˆ"""
    
    # 1. ä¿å­˜æª”æ¡ˆ
    audio_path = await save_uploaded_file(file)
    
    # 2. WhisperX è™•ç†
    transcript_result = processor.process_meeting_audio(audio_path, language)
    
    # 3. OpenRouter åˆ†æ
    analysis = await openrouter.analyze_transcript(
        transcript_result["segments"], 
        analysis_type
    )
    
    return {
        "status": "completed",
        "transcript": transcript_result["segments"],
        "speaker_count": len(set(seg.get("speaker", "UNKNOWN") for seg in transcript_result["segments"])),
        "word_segments": transcript_result.get("word_segments", []),
        "analysis": analysis,
        "processing_time": "å¯¦éš›æ¸¬é‡æ™‚é–“"
    }

@app.post("/analyze-transcript")
async def analyze_transcript(
    transcript: list,
    analysis_type: str
):
    """åˆ†æå·²æœ‰çš„è½‰éŒ„æ–‡å­—"""
    analysis = await openrouter.analyze_transcript(transcript, analysis_type)
    return {"analysis": analysis}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "whisperx": "ready"}
```

#### Day 5-6: å‰ç«¯ PWA æ›´æ–°

**æ›´æ–°éŒ„éŸ³è™•ç†æµç¨‹**
```javascript
// src/recorder.js
class MeetingRecorder {
    constructor() {
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.isRecording = false;
        this.macMiniUrl = 'http://your-mac-mini-ip:8000';
    }
    
    async startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                }
            });
            
            this.mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });
            
            this.mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    this.audioChunks.push(e.data);
                }
            };
            
            this.mediaRecorder.onstop = () => {
                this.processRecording();
            };
            
            this.mediaRecorder.start(1000); // æ¯ç§’æ”¶é›†ä¸€æ¬¡è³‡æ–™
            this.isRecording = true;
            this.updateUI('recording');
            
        } catch (error) {
            console.error('éŒ„éŸ³å¤±æ•—:', error);
            this.showError('ç„¡æ³•å­˜å–éº¥å…‹é¢¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™è¨­å®š');
        }
    }
    
    async stopRecording() {
        if (this.mediaRecorder && this.isRecording) {
            this.mediaRecorder.stop();
            this.isRecording = false;
            this.updateUI('processing');
        }
    }
    
    async processRecording() {
        try {
            // 1. å»ºç«‹éŸ³è¨Š Blob
            const audioBlob = new Blob(this.audioChunks, { 
                type: 'audio/webm;codecs=opus' 
            });
            
            // 2. é¡¯ç¤ºè™•ç†ç‹€æ…‹
            this.updateProcessingStep('uploading');
            
            // 3. ä¸Šå‚³åˆ° Mac Mini è™•ç†
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.webm');
            formData.append('language', 'zh');
            formData.append('analysis_type', this.getSelectedAnalysisType());
            
            const response = await fetch(`${this.macMiniUrl}/process-audio`, {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                throw new Error(`è™•ç†å¤±æ•—: ${response.statusText}`);
            }
            
            this.updateProcessingStep('analyzing');
            
            const result = await response.json();
            
            // 4. é¡¯ç¤ºçµæœ
            this.displayResults(result);
            
            // 5. æ¸…ç†
            this.audioChunks = [];
            
        } catch (error) {
            console.error('è™•ç†éŒ¯èª¤:', error);
            this.showError('è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡è©¦');
        }
    }
    
    getSelectedAnalysisType() {
        const selectedBtn = document.querySelector('.analysis-btn.selected');
        return selectedBtn ? selectedBtn.dataset.type : 'æœƒè­°æ‘˜è¦';
    }
    
    displayResults(result) {
        const resultsPanel = document.getElementById('resultsPanel');
        const resultContent = document.getElementById('resultContent');
        
        // é¡¯ç¤ºè½‰éŒ„çµæœ
        let transcriptHtml = '<h4>æœƒè­°è½‰éŒ„</h4><div class="transcript">';
        result.transcript.forEach(segment => {
            const speaker = segment.speaker || 'UNKNOWN';
            const text = segment.text;
            const start = segment.start.toFixed(1);
            
            transcriptHtml += `
                <div class="segment">
                    <span class="timestamp">[${start}s]</span>
                    <span class="speaker">${speaker}:</span>
                    <span class="text">${text}</span>
                </div>
            `;
        });
        transcriptHtml += '</div>';
        
        // é¡¯ç¤ºåˆ†æçµæœ
        const analysisHtml = `
            <h4>æ™ºèƒ½åˆ†æ</h4>
            <div class="analysis">
                ${result.analysis.replace(/\n/g, '<br>')}
            </div>
        `;
        
        // é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        const statsHtml = `
            <h4>æœƒè­°çµ±è¨ˆ</h4>
            <div class="stats">
                <p>åƒèˆ‡äººæ•¸: ${result.speaker_count}</p>
                <p>è™•ç†æ™‚é–“: ${result.processing_time}</p>
            </div>
        `;
        
        resultContent.innerHTML = transcriptHtml + analysisHtml + statsHtml;
        
        // åˆ‡æ›é¡¯ç¤º
        document.getElementById('processingPanel').classList.add('hidden');
        resultsPanel.classList.remove('hidden');
    }
}
```

#### Day 7: æ•´åˆæ¸¬è©¦

**ç«¯å°ç«¯æ¸¬è©¦**
- éŒ„éŸ³åŠŸèƒ½æ¸¬è©¦
- ä¸Šå‚³è™•ç†æ¸¬è©¦
- è½‰éŒ„æº–ç¢ºåº¦æ¸¬è©¦
- èªªè©±è€…è¾¨è­˜æ¸¬è©¦
- AI åˆ†æå“è³ªæ¸¬è©¦

### Week 2: å„ªåŒ–èˆ‡éƒ¨ç½²

#### Day 8-9: æ•ˆèƒ½å„ªåŒ–

**Mac Mini å„ªåŒ–**
```python
# æ•ˆèƒ½ç›£æ§
class PerformanceMonitor:
    def __init__(self):
        self.metrics = []
    
    def track_processing_time(self, audio_duration, processing_time):
        ratio = processing_time / audio_duration
        self.metrics.append({
            'timestamp': datetime.now(),
            'audio_duration': audio_duration,
            'processing_time': processing_time,
            'real_time_factor': ratio
        })
        
        # ç›®æ¨™ï¼šReal-time factor < 0.1 (10å€é€Ÿåº¦)
        if ratio > 0.1:
            logger.warning(f"è™•ç†é€Ÿåº¦è¼ƒæ…¢: {ratio:.2f}x")
```

**è¨˜æ†¶é«”å„ªåŒ–**
```python
# æ‰¹æ¬¡è™•ç†å¤§æª”æ¡ˆ
def process_large_audio(audio_path, chunk_size=30):
    """åˆ†å¡Šè™•ç†å¤§å‹éŸ³è¨Šæª”æ¡ˆ"""
    audio = whisperx.load_audio(audio_path)
    total_duration = len(audio) / 16000  # å‡è¨­ 16kHz
    
    results = []
    for start in range(0, int(total_duration), chunk_size):
        end = min(start + chunk_size, total_duration)
        chunk = audio[start*16000:end*16000]
        
        chunk_result = model.transcribe(chunk)
        # èª¿æ•´æ™‚é–“æˆ³
        for segment in chunk_result["segments"]:
            segment["start"] += start
            segment["end"] += start
        
        results.extend(chunk_result["segments"])
        
        # æ¸…ç†è¨˜æ†¶é«”
        del chunk
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
    
    return {"segments": results}
```

#### Day 10-11: éƒ¨ç½²èˆ‡ç›£æ§

**ç³»çµ±æœå‹™è¨­ç½®**
```bash
# systemd æœå‹™æª”æ¡ˆ
sudo tee /etc/systemd/system/whisperx-api.service > /dev/null <<EOF
[Unit]
Description=WhisperX API Service
After=network.target

[Service]
Type=simple
User=your_user
WorkingDirectory=/path/to/backend
Environment=HF_TOKEN=your_token
Environment=OPENROUTER_API_KEY=your_key
ExecStart=/path/to/whisperx-env/bin/python -m uvicorn main:app --host 0.0.0.0 --port 8000
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable whisperx-api
sudo systemctl start whisperx-api
```

**ç›£æ§è¨­ç½®**
```python
# ç°¡å–®ç›£æ§è…³æœ¬
import psutil
import requests
from datetime import datetime

def monitor_system():
    # CPU ä½¿ç”¨ç‡
    cpu_percent = psutil.cpu_percent(interval=1)
    
    # è¨˜æ†¶é«”ä½¿ç”¨
    memory = psutil.virtual_memory()
    
    # GPU ä½¿ç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
    gpu_stats = get_gpu_stats() if torch.cuda.is_available() else None
    
    # API å¥åº·æª¢æŸ¥
    try:
        response = requests.get('http://localhost:8000/health', timeout=5)
        api_status = response.status_code == 200
    except:
        api_status = False
    
    stats = {
        'timestamp': datetime.now().isoformat(),
        'cpu_percent': cpu_percent,
        'memory_percent': memory.percent,
        'api_healthy': api_status,
        'gpu_stats': gpu_stats
    }
    
    # è¨˜éŒ„åˆ°æª”æ¡ˆæˆ–ç™¼é€è­¦å ±
    log_stats(stats)
    
    return stats
```

#### Day 12-13: ä½¿ç”¨è€…æ¸¬è©¦

**æ¸¬è©¦æ¡ˆä¾‹**
1. å–®äººç°¡å ±éŒ„éŸ³
2. 2-3äººå°å‹æœƒè­°
3. 4-6äººå¤§å‹æœƒè­°
4. ä¸­è‹±æ··é›œèªéŸ³
5. èƒŒæ™¯å™ªéŸ³ç’°å¢ƒ

**å“è³ªè©•ä¼°æŒ‡æ¨™**
- è½‰éŒ„æº–ç¢ºç‡ >95%
- èªªè©±è€…è¾¨è­˜æº–ç¢ºç‡ >90%
- è™•ç†é€Ÿåº¦ <0.1x å¯¦æ™‚
- AI åˆ†æç›¸é—œæ€§ >85%

#### Day 14: æ–‡æª”å®Œå–„èˆ‡ç™¼å¸ƒ

**å®Œæˆé …ç›®**
- âœ… æŠ€è¡“æ–‡æª”
- âœ… ä½¿ç”¨æ‰‹å†Š
- âœ… éƒ¨ç½²æŒ‡å—
- âœ… æ•…éšœæ’é™¤
- âœ… æ•ˆèƒ½èª¿æ ¡æŒ‡å—

## ğŸ¯ é‡Œç¨‹ç¢‘æª¢æ ¸

### Week 1 çµæŸæª¢æ ¸
- [ ] Mac Mini ç’°å¢ƒå°±ç·’
- [ ] WhisperX æ­£å¸¸é‹ä½œ
- [ ] FastAPI å¾Œç«¯å®Œæˆ
- [ ] PWA å‰ç«¯æ›´æ–°
- [ ] åŸºæœ¬åŠŸèƒ½ç«¯å°ç«¯æ¸¬è©¦é€šé

### Week 2 çµæŸæª¢æ ¸
- [ ] æ•ˆèƒ½é”æ¨™ï¼ˆ<0.1x å¯¦æ™‚è™•ç†ï¼‰
- [ ] ç³»çµ±æœå‹™ç©©å®šé‹è¡Œ
- [ ] ç›£æ§å‘Šè­¦æ­£å¸¸
- [ ] ä½¿ç”¨è€…æ¸¬è©¦é€šé
- [ ] æ–‡æª”å®Œæ•´

## ğŸš¨ é¢¨éšªç®¡æ§

### æŠ€è¡“é¢¨éšª
- **GPU è¨˜æ†¶é«”ä¸è¶³**: èª¿æ•´ batch_size å’Œ compute_type
- **ä¸­æ–‡è¾¨è­˜æº–ç¢ºç‡**: æ¸¬è©¦ä¸åŒæ¨¡å‹å¤§å°
- **ç¶²è·¯é€£ç·šå•é¡Œ**: å¯¦ä½œæ–·ç·šé‡è©¦æ©Ÿåˆ¶

### é€²åº¦é¢¨éšª
- **ä¾è³´å¥—ä»¶è¡çª**: æå‰æ¸¬è©¦ç›¸å®¹æ€§
- **ç¡¬é«”æ•ˆèƒ½ä¸è¶³**: æº–å‚™é™ç´šæ–¹æ¡ˆ
- **ç¬¬ä¸‰æ–¹æœå‹™ä¸­æ–·**: å¯¦ä½œå‚™ç”¨æ–¹æ¡ˆ

## ğŸ“ˆ å¾ŒçºŒæ“´å±•

### Phase 2 åŠŸèƒ½ (Week 3-4)
- å³æ™‚è½‰éŒ„é¡¯ç¤º
- å¤šèªè¨€è‡ªå‹•åµæ¸¬
- æœƒè­°ç¯„æœ¬å’Œå®¢è£½åŒ–æç¤º
- æ‰¹æ¬¡è™•ç†å¤šå€‹æª”æ¡ˆ

### Phase 3 åŠŸèƒ½ (Month 2)
- æƒ…æ„Ÿåˆ†æ
- é—œéµå­—æå–
- æœƒè­°è©•åˆ†ç³»çµ±
- æ•´åˆè¡Œäº‹æ›†

### Phase 4 åŠŸèƒ½ (Month 3)
- å¤šäººå”ä½œ
- æ¬Šé™ç®¡ç†
- è³‡æ–™åˆ†æå„€è¡¨æ¿
- API é–‹æ”¾çµ¦ç¬¬ä¸‰æ–¹